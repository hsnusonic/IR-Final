<title>Modelling interaction with economic models of search</title>
<author>Leif Azzopardi</author>
<abstract>Understanding how people interact when searching is central to the study of Interactive Information Retrieval (IIR). Most of the prior work has either been conceptual, observational or empirical. While this has led to numerous insights and findings regarding the interaction between users and systems, the theory has lagged behind. In this paper, we extend the recently proposed search economic theory to make the model more realistic. We then derive eight interaction based hypotheses regarding search behaviour. To validate the model, we explore whether the search behaviour of thirty-six participants from a lab based study is consistent with the theory. Our analysis shows that observed search behaviours are in line with predicted search behaviours and that it is possible to provide credible explanations for such behaviours. This work describes a concise and compact representation of search behaviour providing a strong theoretical basis for future IIR research.</abstract>
<ref>C. W. Axelrod. The economic evaluation of information storage and retrieval systems. Information Processing & Management, 13(2):117--124, 1977.</ref>
<ref>Leif Azzopardi, The economics in interactive information retrieval, Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval, July 24-28, 2011, Beijing, China</ref>
<ref>Leif Azzopardi, Economic models of search, Proceedings of the 18th Australasian Document Computing Symposium, p.1-1, December 05-06, 2013, Brisbane, Queensland, Australia</ref>
<ref>Leif Azzopardi , Kalervo Järvelin , Jaap Kamps , Mark D. Smucker, Report on the SIGIR 2010 workshop on the simulation of interaction, ACM SIGIR Forum, v.44 n.2, December 2010</ref>
<ref>Leif Azzopardi , Diane Kelly , Kathy Brennan, How query cost affects search behavior, Proceedings of the 36th international ACM SIGIR conference on Research and development in information retrieval, July 28-August 01, 2013, Dublin, Ireland</ref>
<ref>Feza Baskaya , Heikki Keskustalo , Kalervo JĂ¤rvelin, Time drives interaction: simulating sessions in diverse searching environments, Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval, August 12-16, 2012, Portland, Oregon, USA</ref>
<ref>Feza Baskaya , Heikki Keskustalo , Kalervo JĂ¤rvelin, Modeling behavioral factors ininteractive information retrieval, Proceedings of the 22nd ACM international conference on Conference on information & knowledge management, October 27-November 01, 2013, San Francisco, California, USA</ref>
<ref>M. J. Bates. The design of browsing and berrypicking techniques for the online search interface. Online Information Review, 13(5):407--424, 1989.</ref>
<ref>Marcia J. Bates, Information search tactics, Training and education for online, Taylor Graham Publishing, London, UK, 1990</ref>
<ref>Nicholas J. Belkin, Some(what) grand challenges for information retrieval, ACM SIGIR Forum, v.42 n.1, June 2008</ref>
<ref>N. J. Belkin, R. N. Oddy, and H. M. Brooks. Ask for information retrieval: part i: background and theory; part ii: results of a design study. Journal of Documentation, 38(2) 61--71 and 38(3) 145--164, 1982.</ref>
<ref>U. Birchler and M. Butler. Information Economics. Routledge, 1st edition edition, 2007.</ref>
<ref>J. Brutlag. Speed matters for google web search. In Technical Report,2009, Retrieved online at http://googleresearch.blogspot.com/2009/06/speed-matters.html.</ref>
<ref>M. D. Cooper. A cost model for evaluating information retrieval systems. Journal of the American Society for Information Science, pages 306--312, 1972.</ref>
<ref>Sanda Erdelez, Information encountering: a conceptual framework for accidental information discovery, Proceedings of an international conference on Information seeking in context, p.412-421, August 1997, Tampere, Finland</ref>
<ref>Norbert Fuhr, A probability ranking principle for interactive information retrieval, Information Retrieval, v.11 n.3, p.251-265, June      2008</ref>
<ref>Peter Ingwersen , Kalervo J채rvelin, The Turn: Integration of Information Seeking and Retrieval in Context (The Information Retrieval Series), Springer-Verlag New York, Inc., Secaucus, NJ, 2005</ref>
<ref>Kalervo Järvelin, IR research: systems, interaction, evaluation and theories, ACM SIGIR Forum, v.45 n.2, December 2011</ref>
<ref>Kalervo Järvelin , Jaana Kekäläinen, Cumulated gain-based evaluation of IR techniques, ACM Transactions on Information Systems (TOIS), v.20 n.4, p.422-446, October 2002</ref>
<ref>K. JĂĄrvelin and T. D. Wilson. On conceptual models for information seeking and retrieval research. Information Research, 9(1):9--1, 2003.</ref>
<ref>Diane Kelly , Vijay Deepak Dollu , Xin Fu, The loquacious user: a document-independent source of terms for query expansion, Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval, August 15-19, 2005, Salvador, Brazil</ref>
<ref>D. Kelly and C. Sugimoto. A systematic review of interactive information retrieval evaluation studies, 1967--2006. Journal of the American Society for Information Science and Tech., 64(4):745--770, 2013.</ref>
<ref>Heikki Keskustalo , Kalervo JĂ¤rvelin , Ari Pirkola , Tarun Sharma , Marianne Lykke, Test Collection-Based IR Evaluation Needs Extension toward Sessions --- A Case of Extremely Short Queries, Proceedings of the 5th Asia Information Retrieval Symposium on Information Retrieval Technology, October 21-23, 2009, Sapporo, Japan</ref>
<ref>C. C. Kuhlthau. Developing a model of the library search process: Cognitive and affective aspects. RQ, pages 232--242, 1988.</ref>
<ref>P. Pirolli and S. Card. Information foraging. Psychological Review, 106:643--675, 1999.</ref>
<ref>Peter Pirolli , Wai-Tat Fu, SNIF-ACT: a model of information foraging on the world wide web, Proceedings of the 9th international conference on User modeling, June 22-26, 2003, Johnstown, PA, USA</ref>
<ref>Peter Pirolli , Patricia Schank , Marti Hearst , Christine Diehl, Scatter/gather browsing communicates the topic structure of a very large text collection, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, p.213-220, April 13-18, 1996, Vancouver, British Columbia, Canada</ref>
<ref>S. E. Robertson. The probability ranking principle in ir. Journal of documentation, 33(4):294--304, 1977.</ref>
<ref>D. H. Rothenberg. An efficiency model and a performance function for an ir system. Information Storage and Retrieval, 5(3):109--122, 1969.</ref>
<ref>Daniel M. Russell , Mark J. Stefik , Peter Pirolli , Stuart K. Card, The cost structure of sensemaking, Proceedings of the INTERCHI '93 conference on Human factors in computing systems, p.269-276, May 1993, Amsterdam, The Netherlands</ref>
<ref>Tetsuya Sakai , Zhicheng Dou, Summaries, ranked retrieval and sessions: a unified framework for information access evaluation, Proceedings of the 36th international ACM SIGIR conference on Research and development in information retrieval, July 28-August 01, 2013, Dublin, Ireland</ref>
<ref>M. Sanderson. Test collection based evaluation of information retrieval systems. FNTIR, 2010.</ref>
<ref>Catherine L. Smith , Paul B. Kantor, User adaptation: good results from poor systems, Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval, July 20-24, 2008, Singapore, Singapore</ref>
<ref>Mark D. Smucker , Charles L.A. Clarke, Time-based calibration of effectiveness measures, Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval, August 12-16, 2012, Portland, Oregon, USA</ref>
<ref>G. J. Stigler. The economics of information. The Journal of Political Economy, 69(3):213--225, 1961.</ref>
<ref>Shanu Sushmita , Hideo Joho , Mounia Lalmas , Robert Villa, Factors affecting click-through behavior in aggregated search interfaces, Proceedings of the 19th ACM international conference on Information and knowledge management, October 26-30, 2010, Toronto, ON, Canada</ref>
<ref>Andrew Turpin , William Hersh, User interface effects in past batch versus user experiments, Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrieval, August 11-15, 2002, Tampere, Finland</ref>
<ref>Andrew H. Turpin , William Hersh, Why batch and user evaluations do not give the same results, Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, p.225-231, September 2001, New Orleans, Louisiana, USA</ref>
<ref>H. R. Varian. Intermediate microeconomics: A modern approach. W.W. Norton, New York:, 1987.</ref>
<ref>Hal R. Varian, Economics and search, ACM SIGIR Forum, v.33 n.1, p.1-5, Fall 1999</ref>
<ref>Jun Wang , Jianhan Zhu, Portfolio theory of information retrieval, Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval, July 19-23, 2009, Boston, MA, USA</ref>
<ref>Ryen White, Beliefs and biases in web search, Proceedings of the 36th international ACM SIGIR conference on Research and development in information retrieval, July 28-August 01, 2013, Dublin, Ireland</ref>
<ref>Ryen W. White , Susan T. Dumais , Jaime Teevan, Characterizing the influence of domain expertise on web search behavior, Proceedings of the Second ACM International Conference on Web Search and Data Mining, February 09-12, 2009, Barcelona, Spain</ref>
<ref>Ryen W. White , Dan Morris, Investigating the querying and browsing behavior of advanced search engine users, Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval, July 23-27, 2007, Amsterdam, The Netherlands</ref>
<ref>Ryen W. White , Ian Ruthven , Joemon M. Jose , C. J. Van Rijsbergen, Evaluating implicit feedback models using searcher simulations, ACM Transactions on Information Systems (TOIS), v.23 n.3, p.325-361, July 2005</ref>
<ref>T. D. Wilson. Human information behavior. Informing science, 3(2):49--56, 2000.</ref>
<citeby>ne Yilmaz , Manisha Verma , Nick Craswell , Filip Radlinski , Peter Bailey, Relevance and Effort: An Analysis of Document Utility, Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management, November 03-07, 2014, Shanghai, China</citeby>
<citeby>pu Jiang , Ahmed Hassan Awadallah , Xiaolin Shi , Ryen W. White, Understanding and Predicting Graded Search Satisfaction, Proceedings of the Eighth ACM International Conference on Web Search and Data Mining, February 02-06, 2015, Shanghai, China</citeby>





<title>Query-performance prediction: setting the expectations straight</title>
<author>Fiana Raiber</author>
<author>Oren Kurland</author>
<abstract>The query-performance prediction task has been described as estimating retrieval effectiveness in the absence of relevance judgments. The expectations throughout the years were that improved prediction techniques would translate to improved retrieval approaches. However, this has not yet happened. Herein we provide an in-depth analysis of why this is the case. To this end, we formalize the prediction task in the most general probabilistic terms. Using this formalism we draw novel connections between tasks --- and methods used to address these tasks --- in federated search, fusion-based retrieval, and query-performance prediction. Furthermore, using formal arguments we show that the ability to estimate the probability of effective retrieval with no relevance judgments (i.e., to predict performance) implies knowledge of how to perform effective retrieval. We also explain why the expectation that using previously proposed query-performance predictors would help to improve retrieval effectiveness was not realized. This is due to a misalignment with the actual goal for which these predictors were devised: ranking queries based on the presumed effectiveness of using them for retrieval over a corpus with a specific retrieval method. Focusing on this specific prediction task, namely query ranking by presumed effectiveness, we present a novel learning-to-rank-based approach that uses Markov Random Fields. The resultant prediction quality substantially transcends that of state-of-the-art predictors.</abstract>
<ref>J. Allan, M. E. Connell, W. B. Croft, F.-F. Feng, D. Fisher, and X. Li. INQUERY and TREC-9. In Proc. of TREC-9, pages 551--562, 2000.</ref>
<ref>G. Amati, C. Carpineto, and G. Romano. Query difficulty, robustness, and selective application of query expansion. In Proc. of ECIR, pages 127--137, 2004.</ref>
<ref>Christopher C. Vogt , Garrison W. Cottrell, Fusion Via a Linear Combination of Scores, Information Retrieval, v.1 n.3, p.151-173, October 1999</ref>
<ref>Javed A. Aslam , Virgil Pavlu, Query hardness estimation using Jensen-Shannon divergence among multiple scoring functions, Proceedings of the 29th European conference on IR research, April 02-05, 2007, Rome, Italy</ref>
<ref>Niranjan Balasubramanian , James Allan, Learning to select rankers, Proceedings of the 33rd international ACM SIGIR conference on Research and development in information retrieval, July 19-23, 2010, Geneva, Switzerland</ref>
<ref>Niranjan Balasubramanian , Giridhar Kumaran , Vitor R. Carvalho, Predicting query performance on the web, Proceedings of the 33rd international ACM SIGIR conference on Research and development in information retrieval, July 19-23, 2010, Geneva, Switzerland</ref>
<ref>Steven M. Beitzel , Ophir Frieder , Eric C. Jensen , David Grossman , Abdur Chowdhury , Nazli Goharian, Disproving the fusion hypothesis: an analysis of data fusion via effective information retrieval strategies, Proceedings of the 2003 ACM symposium on Applied computing, March 09-12, 2003, Melbourne, Florida</ref>
<ref>Michael Bendersky , W. Bruce Croft , Yanlei Diao, Quality-biased ranking of web documents, Proceedings of the fourth ACM international conference on Web search and data mining, February 09-12, 2011, Hong Kong, China</ref>
<ref>Y. Bernstein, B. Billerbeck, S. Garcia, N. Lester, F. Scholer, and J. Zobel. RMIT university at trec 2005: Terabyte and robust track. In Proc. of TREC-14, 2005.</ref>
<ref>J. Callan. Distributed information retrieval. In W. Croft, editor, Advances in information retrieval, chapter 5, pages 127--150. Kluwer Academic Publishers, 2000.</ref>
<ref>David Carmel , Elad Yom-Tov, Estimating the Query Difficulty for Information Retrieval, Morgan and Claypool Publishers, 2010</ref>
<ref>David Carmel , Elad Yom-Tov , Adam Darlow , Dan Pelleg, What makes a query difficult?, Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, August 06-11, 2006, Seattle, Washington, USA</ref>
<ref>Gordon V. Cormack , Mark D. Smucker , Charles L. Clarke, Efficient and effective spam filtering and re-ranking for large web datasets, Information Retrieval, v.14 n.5, p.441-465, October   2011</ref>
<ref>W. B. Croft. Combining approaches to information retrieval. In W. B. Croft, editor, Advances in information retrieval, chapter 1, pages 1--36. Kluwer Academic Publishers, 2000.</ref>
<ref>Steve Cronen-Townsend , Yun Zhou , W. Bruce Croft, Predicting query performance, Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrieval, August 11-15, 2002, Tampere, Finland</ref>
<ref>S. Cronen-Townsend, Y. Zhou, and W. B. Croft. A language modeling framework for selective query expansion. Technical Report IR-338, Center for Intelligent Information Retrieval, University of Massachusetts, 2004.</ref>
<ref>Ronan Cummins, Predicting query performance directly from score distributions, Proceedings of the 7th Asia conference on Information Retrieval Technology, December 18-20, 2011, Dubai, United Arab Emirates</ref>
<ref>Ronan Cummins , Joemon Jose , Colm O'Riordan, Improved query performance prediction using standard deviation, Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval, July 24-28, 2011, Beijing, China</ref>
<ref>Fernando Diaz, Performance prediction using spatial autocorrelation, Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval, July 23-27, 2007, Amsterdam, The Netherlands</ref>
<ref>E. A. Fox and J. A. Shaw. Combination of multiple searches. In Proc. of TREC-2, 1994.</ref>
<ref>Claudia Hauff , Leif Azzopardi, When is query performance prediction effective?, Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval, July 19-23, 2009, Boston, MA, USA</ref>
<ref>Claudia Hauff , Leif Azzopardi , Djoerd Hiemstra, The Combination and Evaluation of Query Performance Prediction Methods, Proceedings of the 31th European Conference on IR Research on Advances in Information Retrieval, April 06-09, 2009, Toulouse, France</ref>
<ref>Claudia Hauff , Djoerd Hiemstra , Franciska de Jong, A survey of pre-retrieval query performance predictors, Proceedings of the 17th ACM conference on Information and knowledge management, October 26-30, 2008, Napa Valley, California, USA</ref>
<ref>Claudia Hauff , Vanessa Murdock , Ricardo Baeza-Yates, Improved query difficulty prediction for the web, Proceedings of the 17th ACM conference on Information and knowledge management, October 26-30, 2008, Napa Valley, California, USA</ref>
<ref>B. He and I. Ounis. Inferring query performance using pre-retrieval predictors. In Proc. of SPIRE, pages 43--54, 2004.</ref>
<ref>Thorsten Joachims, Training linear SVMs in linear time, Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining, August 20-23, 2006, Philadelphia, PA, USA</ref>
<ref>Oren Kurland , Fiana Raiber , Anna Shtok, Query-performance prediction and cluster ranking: two sides of the same coin, Proceedings of the 21st ACM international conference on Information and knowledge management, October 29-November 02, 2012, Maui, Hawaii, USA</ref>
<ref>Oren Kurland , Anna Shtok , David Carmel , Shay Hummel, A unified framework for post-retrieval query-performance prediction, Proceedings of the Third international conference on Advances in information retrieval theory, September 12-14, 2011, Bertinoro, Italy</ref>
<ref>Oren Kurland , Anna Shtok , Shay Hummel , Fiana Raiber , David Carmel , Ofri Rom, Back to the roots: a probabilistic framework for query-performance prediction, Proceedings of the 21st ACM international conference on Information and knowledge management, October 29-November 02, 2012, Maui, Hawaii, USA</ref>
<ref>Victor Lavrenko , W. Bruce Croft, Relevance based language models, Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, p.120-127, September 2001, New Orleans, Louisiana, USA</ref>
<ref>David Lillis , Fergus Toolan , Rem Collier , John Dunnion, ProbFuse: a probabilistic approach to data fusion, Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, August 06-11, 2006, Seattle, Washington, USA</ref>
<ref>T.-Y. Liu. Learning to Rank for Information Retrieval. Springer, 2011.</ref>
<ref>Xiaoyong Liu , W. Bruce Croft, Cluster-based retrieval using language models, Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, July 25-29, 2004, Sheffield, United Kingdom</ref>
<ref>X. Liu and W. B. Croft. Experiments on retrieval of optimal clusters. Technical Report IR-478, Center for Intelligent Information Retrieval (CIIR), University of Massachusetts, 2006.</ref>
<ref>Craig Macdonald , Rodrygo L.T. Santos , Iadh Ounis, On the usefulness of query features for learning to rank, Proceedings of the 21st ACM international conference on Information and knowledge management, October 29-November 02, 2012, Maui, Hawaii, USA</ref>
<ref>Donald Metzler , W. Bruce Croft, A Markov random field model for term dependencies, Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval, August 15-19, 2005, Salvador, Brazil</ref>
<ref>J. Mothe and L. Tanguy. Linguistic features to predict query difficulty. In ACM SIGIR 2005 Workshop on Predicting Query Difficulty - Methods and Applications, 2005.</ref>
<ref>JoaquĂ­n PĂŠrez-Iglesias , Lourdes Araujo, Standard deviation as a query hardness estimator, Proceedings of the 17th international conference on String processing and information retrieval, October 11-13, 2010, Los Cabos, Mexico</ref>
<ref>Fiana Raiber , Oren Kurland, Ranking document clusters using markov random fields, Proceedings of the 36th international ACM SIGIR conference on Research and development in information retrieval, July 28-August 01, 2013, Dublin, Ireland</ref>
<ref>Fiana Raiber , Oren Kurland, Using document-quality measures to predict web-search effectiveness, Proceedings of the 35th European conference on Advances in Information Retrieval, March 24-27, 2013, Moscow, Russia</ref>
<ref>Falk Scholer , Steven Garcia, A case for improved evaluation of query difficulty prediction, Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval, July 19-23, 2009, Boston, MA, USA</ref>
<ref>Falk Scholer , Hugh E. Williams , Andrew Turpin, Query association surrogates for Web search: Research Articles, Journal of the American Society for Information Science and Technology, v.55 n.7, p.637-650, May 2004</ref>
<ref>Daniel Sheldon , Milad Shokouhi , Martin Szummer , Nick Craswell, LambdaMerge: merging the results of query reformulations, Proceedings of the fourth ACM international conference on Web search and data mining, February 09-12, 2011, Hong Kong, China</ref>
<ref>Milad Shokouhi , Luo Si, Federated Search, Foundations and Trends in Information Retrieval, v.5 n.1, p.1-102, January 2011</ref>
<ref>Anna Shtok , Oren Kurland , David Carmel, Using statistical decision theory and relevance models for query-performance prediction, Proceedings of the 33rd international ACM SIGIR conference on Research and development in information retrieval, July 19-23, 2010, Geneva, Switzerland</ref>
<ref>Anna Shtok , Oren Kurland , David Carmel , Fiana Raiber , Gad Markovits, Predicting Query Performance by Query-Drift Estimation, ACM Transactions on Information Systems (TOIS), v.30 n.2, p.1-35, May 2012</ref>
<ref>Ian Soboroff , Charles Nicholas , Patrick Cahan, Ranking retrieval systems without relevance judgments, Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, p.66-73, September 2001, New Orleans, Louisiana, USA</ref>
<ref>Fei Song , W. Bruce Croft, A general language model for information retrieval (poster abstract), Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval, p.279-280, August 15-19, 1999, Berkeley, California, USA</ref>
<ref>K. Sparck Jones , S. Walker , S. E. Robertson, A probabilistic model of information retrieval: development and comparative experiments, Information Processing and Management: an International Journal, v.36 n.6, p.779-808, Nov.06.2000</ref>
<ref>S. Tomlinson. Robust, Web and Terabyte Retrieval with Hummingbird Search Server at TREC 2004. In Proc. of TREC-13, 2004.</ref>
<ref>Vishwa Vinay , Ingemar J. Cox , Natasa Milic-Frayling , Ken Wood, On ranking the effectiveness of searches, Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, August 06-11, 2006, Seattle, Washington, USA</ref>
<ref>Elad Yom-Tov , Shai Fine , David Carmel , Adam Darlow, Learning to estimate query difficulty: including applications to missing content detection and distributed information retrieval, Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval, August 15-19, 2005, Salvador, Brazil</ref>
<ref>Ying Zhao , Falk Scholer , Yohannes Tsegay, Effective pre-retrieval query performance prediction using similarity and variability evidence, Proceedings of the IR research, 30th European conference on Advances in information retrieval, March 30-April 03, 2008, Glasgow, UK</ref>
<ref>Yun Zhou , W. Bruce Croft, Ranking robustness: a novel framework to predict query performance, Proceedings of the 15th ACM international conference on Information and knowledge management, November 06-11, 2006, Arlington, Virginia, USA</ref>
<ref>Yun Zhou , W. Bruce Croft, Query performance prediction in web search environments, Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval, July 23-27, 2007, Amsterdam, The Netherlands</ref>
<citeby> Khanh Tran , Andrea Ceroni , Nattiya Kanhabua , Claudia NiederÄĹ e, Back to the Past: Supporting Interpretations of Forgotten Stories by Time-aware Re-Contextualization, Proceedings of the Eighth ACM International Conference on Web Search and Data Mining, February 02-06, 2015, Shanghai, China</citeby>





